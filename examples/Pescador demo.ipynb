{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pescador demo\n",
    "\n",
    "This notebook illustrates some of the basic functionality of [pescador](https://github.com/bmcfee/pescador): a package to facilitate iterative learning from data streams (implemented as python generators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pescador\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(X, Y, m=20, scale = 1e-1):\n",
    "    '''A gaussian noise generator for data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        features, n_samples by dimensions\n",
    "        \n",
    "    Y : ndarray\n",
    "        labels, n_samples\n",
    "        \n",
    "    m : int\n",
    "        size of the minibatches to generate\n",
    "        \n",
    "    scale : float > 0\n",
    "        scale of the noise to add\n",
    "        \n",
    "    Generates\n",
    "    ---------\n",
    "    batch\n",
    "        An infinite stream of batch dictionaries\n",
    "        batch = dict(X=X[i], Y=Y[i])\n",
    "    '''\n",
    "    \n",
    "    X = np.atleast_2d(X)\n",
    "    Y = np.atleast_1d(Y)\n",
    "\n",
    "    \n",
    "    n, d = X.shape\n",
    "    \n",
    "    while True:\n",
    "        i = np.random.randint(0, n, size=m)\n",
    "        \n",
    "        noise = scale * np.random.randn(m, d)\n",
    "        \n",
    "        yield {'X': X[i] + noise, 'Y': Y[i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load up the iris dataset for the demo\n",
    "data = sklearn.datasets.load_iris()\n",
    "X, Y = data.data, data.target\n",
    "classes = np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Y': array([1, 2, 0]), 'X': array([[ 5.8958,  3.2539,  4.7756,  1.9052],\n",
      "       [ 6.376 ,  2.9074,  4.866 ,  1.8192],\n",
      "       [ 4.3881,  3.0593,  1.3687,  0.3059]])}\n",
      "{'Y': array([2, 2, 0]), 'X': array([[ 6.7266,  2.4949,  5.9466,  1.7307],\n",
      "       [ 5.8329,  2.696 ,  5.0676,  1.8783],\n",
      "       [ 5.4087,  3.6965,  1.3133,  0.2138]])}\n",
      "{'Y': array([0, 0, 2]), 'X': array([[ 5.1651,  3.5178,  1.4245,  0.0344],\n",
      "       [ 4.5477,  3.3718,  1.413 ,  0.2002],\n",
      "       [ 6.2034,  2.895 ,  5.6942,  1.8306]])}\n",
      "{'Y': array([1, 0, 2]), 'X': array([[ 5.7593,  2.6121,  4.1147,  1.2895],\n",
      "       [ 5.0935,  3.5156,  1.5837,  0.4479],\n",
      "       [ 6.3018,  3.2887,  5.509 ,  2.3479]])}\n",
      "{'Y': array([0, 1, 2]), 'X': array([[ 4.8191,  3.3147,  1.7729,  0.0847],\n",
      "       [ 5.5358,  2.2858,  3.9109,  1.3077],\n",
      "       [ 6.4131,  3.3305,  5.097 ,  2.0368]])}\n",
      "{'Y': array([0, 0, 1]), 'X': array([[ 4.3614,  3.2456,  1.3656,  0.0904],\n",
      "       [ 4.8729,  3.1725,  1.2827,  0.1916],\n",
      "       [ 5.951 ,  3.1406,  4.6995,  1.7543]])}\n",
      "{'Y': array([0, 0]), 'X': array([[ 5.3575,  3.7896,  1.4426,  0.1424],\n",
      "       [ 5.401 ,  3.7505,  1.2751,  0.2905]])}\n"
     ]
    }
   ],
   "source": [
    "# What does the data stream look like?\n",
    "\n",
    "# First, we'll wrap the generator function in a Streamer object.\n",
    "# This is necessary for a few reasons, notably so that we can re-instantiate\n",
    "# the generator multiple times (eg once per epoch)\n",
    "\n",
    "stream = pescador.Streamer(data_generator, X, Y)\n",
    "\n",
    "# The buffer_batch() function takes a batch stream as input, and\n",
    "# carves it into batches of up to buffer_size (3, in this case) samples\n",
    "# the buffer size can be larger or smaller than the native size of the input batches\n",
    "for q in pescador.buffer_batch(stream.generate(max_batches=1), 3):\n",
    "    print q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "We can benchmark our learner's efficiency by running a couple of experiments on the Iris dataset.\n",
    "\n",
    "Our classifier will be L1-regularized logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set accuracy: 0.733\n",
      "# Steps: 5001.0\n",
      "Test-set accuracy: 0.867\n",
      "# Steps: 5001.0\n",
      "CPU times: user 195 ms, sys: 2.08 ms, total: 197 ms\n",
      "Wall time: 198 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for train, test in sklearn.cross_validation.ShuffleSplit(len(X),\n",
    "                                                         n_iter=2,\n",
    "                                                         test_size=0.2):\n",
    "    \n",
    "    # Make an SGD learner, nothing fancy here\n",
    "    classifier = sklearn.linear_model.SGDClassifier(verbose=0, \n",
    "                                                    loss='log',\n",
    "                                                    penalty='l1', \n",
    "                                                    n_iter=1)\n",
    "    \n",
    "    # Make a streamable wrapper\n",
    "    model = pescador.StreamLearner(classifier)\n",
    "    \n",
    "    # Again, build a streamer object\n",
    "    stream = pescador.Streamer(data_generator, X[train], Y[train])\n",
    "    \n",
    "    # we'll buffer into batches of 16 samples each\n",
    "    samples = pescador.buffer_batch(stream.generate(max_batches=5e3//20),\n",
    "                                    20)\n",
    "    \n",
    "    # And train the model on the stream.\n",
    "    # iter_fit() works just like partial_fit(), except that the input is a generator.\n",
    "    model.iter_fit(samples, classes=classes)\n",
    "    \n",
    "    # How's it do on the test set?\n",
    "    print 'Test-set accuracy: {:.3f}'.format(sklearn.metrics.accuracy_score(Y[test], model.predict(X[test])))\n",
    "    print '# Steps: ' + str(model.estimator.t_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism\n",
    "\n",
    "It's possible that the learner is more or less efficient than the data generator.  If the data generator has higher latency than the learner (SGDClassifier), then this will slow down the learning.\n",
    "\n",
    "Pescador uses zeromq to parallelize data stream generation, effectively decoupling it from the learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zmq_stream() got an unexpected keyword argument 'max_batches'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6e9a03ed163d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu\"for train, test in sklearn.cross_validation.ShuffleSplit(len(X), n_iter=2, test_size=0.2):\\n    \\n    # Make an SGD learner, nothing fancy here\\n    classifier = sklearn.linear_model.SGDClassifier(verbose=0, \\n                                                    loss='log',\\n                                                    penalty='l1', \\n                                                    n_iter=1)\\n    \\n    # Make a streamable wrapper\\n    model = pescador.StreamLearner(classifier)\\n    \\n    # First, turn the data_generator function into a Streamer object\\n    stream = pescador.Streamer(data_generator, X[train], Y[train])\\n    \\n    # Then, send this thread to a second process\\n    zmq_stream = pescador.zmq_stream(5156, stream, max_batches=5e3//20)\\n    \\n    # Run the output through a second buffer for mini-batch training\\n    samples = pescador.buffer_batch(zmq_stream, 20)\\n    \\n    # And fit on the stream\\n    model.iter_fit(samples, classes=classes)\\n    \\n    # How's it do on the test set?\\n    print 'Test-set accuracy: {:.3f}'.format(sklearn.metrics.accuracy_score(Y[test], model.predict(X[test])))\\n    print '# Steps: ' + str(model.estimator.t_)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2259\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2260\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2261\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2262\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: zmq_stream() got an unexpected keyword argument 'max_batches'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for train, test in sklearn.cross_validation.ShuffleSplit(len(X), n_iter=2, test_size=0.2):\n",
    "    \n",
    "    # Make an SGD learner, nothing fancy here\n",
    "    classifier = sklearn.linear_model.SGDClassifier(verbose=0, \n",
    "                                                    loss='log',\n",
    "                                                    penalty='l1', \n",
    "                                                    n_iter=1)\n",
    "    \n",
    "    # Make a streamable wrapper\n",
    "    model = pescador.StreamLearner(classifier)\n",
    "    \n",
    "    # First, turn the data_generator function into a Streamer object\n",
    "    stream = pescador.Streamer(data_generator, X[train], Y[train])\n",
    "    \n",
    "    # Then, send this thread to a second process\n",
    "    zmq_stream = pescador.zmq_stream(5156, stream, max_batches=5e3//20)\n",
    "    \n",
    "    # Run the output through a second buffer for mini-batch training\n",
    "    samples = pescador.buffer_batch(zmq_stream, 20)\n",
    "    \n",
    "    # And fit on the stream\n",
    "    model.iter_fit(samples, classes=classes)\n",
    "    \n",
    "    # How's it do on the test set?\n",
    "    print 'Test-set accuracy: {:.3f}'.format(sklearn.metrics.accuracy_score(Y[test], model.predict(X[test])))\n",
    "    print '# Steps: ' + str(model.estimator.t_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
