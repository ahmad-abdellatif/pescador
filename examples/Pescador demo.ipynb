{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pescador demo\n",
    "\n",
    "This notebook illustrates some of the basic functionality of [pescador](https://github.com/bmcfee/pescador): a package to facilitate iterative learning from data streams (implemented as python generators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pescador\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_sampler(X, Y, batch_size=20, scale = 1e-1):\n",
    "    '''A gaussian noise generator for data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        features, n_samples by dimensions\n",
    "        \n",
    "    Y : ndarray\n",
    "        labels, n_samples\n",
    "        \n",
    "    batch_size : int\n",
    "        size of the minibatches to generate\n",
    "        \n",
    "    scale : float > 0\n",
    "        scale of the noise to add\n",
    "        \n",
    "    Generates\n",
    "    ---------\n",
    "    data\n",
    "        An infinite stream of data dictionaries\n",
    "        batch = dict(X=X[i], Y=Y[i])\n",
    "    '''\n",
    "    \n",
    "    X = np.atleast_2d(X)\n",
    "    Y = np.atleast_1d(Y)\n",
    "\n",
    "    \n",
    "    n, d = X.shape\n",
    "    \n",
    "    while True:\n",
    "        i = np.random.randint(0, n, size=batch_size)\n",
    "        \n",
    "        noise = scale * np.random.randn(batch_size, d)\n",
    "        \n",
    "        yield {'X': X[i] + noise, 'Y': Y[i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load up the iris dataset for the demo\n",
    "data = sklearn.datasets.load_iris()\n",
    "X, Y = data.data, data.target\n",
    "classes = np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': array([[ 4.4258,  3.1112,  1.3129,  0.2198],\n",
      "       [ 4.9799,  3.5101,  1.364 ,  0.4528],\n",
      "       [ 6.1828,  2.1968,  4.3321,  1.4157],\n",
      "       [ 5.0051,  2.3551,  3.2314,  0.9696],\n",
      "       [ 5.8826,  2.8636,  4.3867,  1.6251],\n",
      "       [ 5.9263,  2.8091,  4.1766,  1.0761],\n",
      "       [ 4.562 ,  3.2333,  1.4327,  0.2532],\n",
      "       [ 7.3517,  2.8017,  6.1302,  2.057 ],\n",
      "       [ 6.5248,  2.9433,  5.867 ,  2.2307],\n",
      "       [ 5.6243,  2.7135,  4.267 ,  1.3158],\n",
      "       [ 4.4369,  3.1829,  1.3174,  0.2398],\n",
      "       [ 4.9293,  3.0768,  1.4912,  0.1628],\n",
      "       [ 5.7435,  2.5492,  3.5466,  0.8201],\n",
      "       [ 5.5816,  4.1874,  1.5755,  0.5114],\n",
      "       [ 7.3886,  3.5892,  6.0697,  2.6535],\n",
      "       [ 5.6016,  2.6809,  4.1578,  1.2411],\n",
      "       [ 6.3535,  3.42  ,  6.1856,  2.5321],\n",
      "       [ 6.1428,  2.6925,  5.5733,  1.4021],\n",
      "       [ 4.9861,  3.2372,  1.7598,  0.3836],\n",
      "       [ 6.4367,  2.3859,  5.8194,  1.7669]]), 'Y': array([0, 0, 1, 1, 1, 1, 0, 2, 2, 1, 0, 0, 1, 0, 2, 1, 2, 2, 0, 2])}\n",
      "{'X': array([[ 5.4006,  4.1489,  1.5627,  0.2354],\n",
      "       [ 5.8643,  2.4767,  3.9196,  1.2635],\n",
      "       [ 7.7248,  2.8787,  6.7759,  1.937 ],\n",
      "       [ 5.4541,  3.6686,  1.4243,  0.2001],\n",
      "       [ 7.944 ,  3.7218,  6.2846,  2.0293],\n",
      "       [ 6.4046,  2.6964,  5.497 ,  2.0121],\n",
      "       [ 4.907 ,  2.3577,  4.4331,  1.5035],\n",
      "       [ 5.2309,  3.3794,  1.4426,  0.6711],\n",
      "       [ 4.9332,  3.1473,  1.6354,  0.2213],\n",
      "       [ 5.9293,  2.7036,  3.8511,  1.29  ],\n",
      "       [ 5.7858,  2.4233,  3.9115,  1.037 ],\n",
      "       [ 4.8445,  3.0735,  1.5496,  0.2076],\n",
      "       [ 7.0921,  3.7038,  6.0055,  2.4472],\n",
      "       [ 5.2373,  2.2789,  2.9361,  0.9508],\n",
      "       [ 5.8564,  2.5985,  3.4276,  0.9927],\n",
      "       [ 7.7707,  2.7053,  6.6353,  1.9698],\n",
      "       [ 6.5882,  3.0069,  4.5496,  1.4054],\n",
      "       [ 7.9983,  3.6455,  6.3562,  2.0261],\n",
      "       [ 5.6892,  2.7705,  5.0896,  2.3305],\n",
      "       [ 5.4506,  3.5979,  1.4419,  0.3277]]), 'Y': array([0, 1, 2, 0, 2, 2, 2, 0, 0, 1, 1, 0, 2, 1, 1, 2, 1, 2, 2, 0])}\n",
      "{'X': array([[ 5.6808,  2.794 ,  5.1394,  1.834 ],\n",
      "       [ 5.1402,  3.4474,  1.5758,  0.3242],\n",
      "       [ 6.9582,  3.1497,  4.8439,  1.3205],\n",
      "       [ 5.1385,  3.4029,  1.7577,  0.7445],\n",
      "       [ 6.6509,  3.2288,  5.9159,  2.2224],\n",
      "       [ 5.4502,  3.9176,  1.1924,  0.4798],\n",
      "       [ 6.1775,  3.0006,  4.9417,  1.8244],\n",
      "       [ 4.7371,  3.1337,  1.4098,  0.1238],\n",
      "       [ 5.976 ,  1.9877,  4.0675,  0.937 ],\n",
      "       [ 4.939 ,  3.5439,  1.0957,  0.3607],\n",
      "       [ 5.5374,  3.4114,  1.2487,  0.4112],\n",
      "       [ 6.8033,  3.0698,  5.3864,  2.0485],\n",
      "       [ 5.1687,  3.5103,  1.2541,  0.3091],\n",
      "       [ 5.1002,  3.1303,  1.3174,  0.2296],\n",
      "       [ 7.4721,  2.7944,  6.2278,  1.868 ],\n",
      "       [ 4.799 ,  3.7621,  1.3563,  0.259 ],\n",
      "       [ 4.8656,  3.1615,  1.2278,  0.2431],\n",
      "       [ 6.5452,  3.0624,  5.8322,  2.1631],\n",
      "       [ 5.5798,  3.7316,  1.5406,  0.1533],\n",
      "       [ 7.7141,  2.8549,  6.1217,  2.1333]]), 'Y': array([2, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2])}\n"
     ]
    }
   ],
   "source": [
    "# What does the data stream look like?\n",
    "\n",
    "# First, we'll wrap the generator function in a Streamer object.\n",
    "# This is necessary for a few reasons, notably so that we can re-instantiate\n",
    "# the generator multiple times (eg once per epoch)\n",
    "batches = pescador.Streamer(batch_sampler, X, Y)\n",
    "\n",
    "for q in batches(max_iter=3):\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "We can benchmark our learner's efficiency by running a couple of experiments on the Iris dataset.\n",
    "\n",
    "Our classifier will be L1-regularized logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set accuracy: 0.967\n",
      "# Steps:  5000\n",
      "Test-set accuracy: 1.000\n",
      "# Steps:  5000\n",
      "CPU times: user 8.97 s, sys: 173 ms, total: 9.15 s\n",
      "Wall time: 9.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ss = sklearn.model_selection.ShuffleSplit(n_splits=2, test_size=0.2)\n",
    "for train, test in ss.split(np.arange(len(X))):\n",
    "    \n",
    "    # Make an SGD learner, nothing fancy here\n",
    "    classifier = sklearn.linear_model.SGDClassifier(verbose=0, \n",
    "                                                    loss='log',\n",
    "                                                    penalty='l1', \n",
    "                                                    n_iter=1)\n",
    "    \n",
    "    # Again, build a streamer object\n",
    "    batches = pescador.Streamer(batch_sampler, X[train], Y[train])\n",
    "\n",
    "    # And train the model on the stream.\n",
    "    n_steps = 0\n",
    "    for batch in batches(max_iter=5e3):\n",
    "        classifier.partial_fit(batch['X'], batch['Y'], classes=classes)\n",
    "        \n",
    "        n_steps += 1\n",
    "    \n",
    "    # How's it do on the test set?\n",
    "    print('Test-set accuracy: {:.3f}'.format(sklearn.metrics.accuracy_score(Y[test], classifier.predict(X[test]))))\n",
    "    print('# Steps: ', n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism\n",
    "\n",
    "It's possible that the learner is more or less efficient than the data generator.  If the data generator has higher latency than the learner (SGDClassifier), then this will slow down the learning.\n",
    "\n",
    "Pescador uses zeromq to parallelize data stream generation, effectively decoupling it from the learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set accuracy: 1.000\n",
      "# Steps:  5000\n",
      "Test-set accuracy: 1.000\n",
      "# Steps:  5000\n",
      "CPU times: user 8.77 s, sys: 186 ms, total: 8.95 s\n",
      "Wall time: 9.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ss = sklearn.model_selection.ShuffleSplit(n_splits=2, test_size=0.2)\n",
    "for train, test in ss.split(np.arange(len(X))):\n",
    "    \n",
    "    # Make an SGD learner, nothing fancy here\n",
    "    classifier = sklearn.linear_model.SGDClassifier(verbose=0, \n",
    "                                                    loss='log',\n",
    "                                                    penalty='l1', \n",
    "                                                    n_iter=1)\n",
    "    \n",
    "    # First, turn the data_generator function into a Streamer object\n",
    "    batches = pescador.Streamer(batch_sampler, X[train], Y[train])\n",
    "    \n",
    "    # Then, send this thread to a second process\n",
    "    zmq_stream = pescador.ZMQStreamer(batches, 5156)\n",
    "    \n",
    "    # And train the model on the stream.\n",
    "    n_steps = 0\n",
    "    for batch in zmq_stream(max_iter=5e3):\n",
    "        classifier.partial_fit(batch['X'], batch['Y'], classes=classes)\n",
    "        \n",
    "        n_steps += 1\n",
    "    \n",
    "    # How's it do on the test set?\n",
    "    print('Test-set accuracy: {:.3f}'.format(sklearn.metrics.accuracy_score(Y[test], classifier.predict(X[test]))))\n",
    "    print('# Steps: ', n_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
